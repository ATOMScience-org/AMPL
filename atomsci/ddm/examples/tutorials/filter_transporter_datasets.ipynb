{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do initial filtering on raw ChEMBL datasets to generate the \"raw\" datasets to be provided to tutorial users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 22:49:10.986131: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-27 22:49:11.034070: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-27 22:49:11.034155: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-27 22:49:11.034211: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-27 22:49:11.044520: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-27 22:49:11.046315: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 22:49:13.178482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n",
      "/usr/WS2/kmelough/ampl161_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from atomsci.ddm.utils.struct_utils import mol_wt_from_smiles, base_smiles_from_smiles\n",
    "from atomsci.ddm.utils.data_curation_functions import compute_negative_log_responses, standardize_relations\n",
    "from atomsci.ddm.utils.curate_data import remove_outlier_replicates, aggregate_assay_data\n",
    "from atomsci.ddm.pipeline import model_pipeline as mp\n",
    "from atomsci.ddm.pipeline import parameter_parser as parse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc6a2_ic50_raw_df = pd.read_csv('dataset/SLC6A2_IC50_raw.csv', sep=';')\n",
    "slc6a3_ic50_raw_df = pd.read_csv('dataset/SLC6A3_IC50_raw.csv', sep=';')\n",
    "slc6a4_ic50_raw_df = pd.read_csv('dataset/SLC6A4_IC50_raw.csv', sep=';')\n",
    "slc6a2_ki_raw_df = pd.read_csv('dataset/SLC6A2_Ki_raw.csv', sep=';')\n",
    "slc6a3_ki_raw_df = pd.read_csv('dataset/SLC6A3_Ki_raw.csv', sep=';')\n",
    "slc6a4_ki_raw_df = pd.read_csv('dataset/SLC6A4_Ki_raw.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dict(\n",
    "    IC50=dict(\n",
    "        SLC6A2=slc6a2_ic50_raw_df,\n",
    "        SLC6A3=slc6a3_ic50_raw_df,\n",
    "        SLC6A4=slc6a4_ic50_raw_df,\n",
    "    ),\n",
    "    Ki=dict(\n",
    "        SLC6A2=slc6a2_ki_raw_df,\n",
    "        SLC6A3=slc6a3_ki_raw_df,\n",
    "        SLC6A4=slc6a4_ki_raw_df,\n",
    "    )\n",
    ")\n",
    "endpoints = list(raw_data.keys())\n",
    "targets = list(raw_data['IC50'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter datasets to remove null values and units, select and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SLC6A2 IC50: 3454 rows\n",
      "Dropped 868 rows with null units\n",
      "Dropped 6 rows with missing or 0/negative values\n",
      "Dropped 1 rows with weird units\n",
      "Row counts by units:\n",
      "standard_units\n",
      "nM    2564\n",
      "µM      15\n",
      "Name: count, dtype: int64\n",
      "Row counts by relation:\n",
      "standard_relation\n",
      "'='    2395\n",
      "'>'     182\n",
      "'<'       2\n",
      "Name: count, dtype: int64\n",
      "Wrote filtered raw data to dataset/SLC6A2_IC50.csv\n",
      "\n",
      "SLC6A3 IC50: 3412 rows\n",
      "Dropped 906 rows with null units\n",
      "Dropped 13 rows with missing or 0/negative values\n",
      "Dropped 1 rows with weird units\n",
      "Row counts by units:\n",
      "standard_units\n",
      "nM    2488\n",
      "µM       4\n",
      "Name: count, dtype: int64\n",
      "Row counts by relation:\n",
      "standard_relation\n",
      "'='    2051\n",
      "'>'     435\n",
      "'<'       4\n",
      "Name: count, dtype: int64\n",
      "Wrote filtered raw data to dataset/SLC6A3_IC50.csv\n",
      "\n",
      "SLC6A4 IC50: 4530 rows\n",
      "Dropped 919 rows with null units\n",
      "Dropped 19 rows with missing or 0/negative values\n",
      "Dropped 1 rows with weird units\n",
      "Row counts by units:\n",
      "standard_units\n",
      "nM    3590\n",
      "µM       1\n",
      "Name: count, dtype: int64\n",
      "Row counts by relation:\n",
      "standard_relation\n",
      "'='    3170\n",
      "'>'     417\n",
      "'<'       3\n",
      "Name: count, dtype: int64\n",
      "Wrote filtered raw data to dataset/SLC6A4_IC50.csv\n",
      "\n",
      "SLC6A2 Ki: 3005 rows\n",
      "Dropped 822 rows with null units\n",
      "Dropped 2 rows with missing or 0/negative values\n",
      "Dropped 0 rows with weird units\n",
      "Row counts by units:\n",
      "standard_units\n",
      "nM    2180\n",
      "µM       1\n",
      "Name: count, dtype: int64\n",
      "Row counts by relation:\n",
      "standard_relation\n",
      "'='     1948\n",
      "'>'      211\n",
      "'<'        7\n",
      "'>='       2\n",
      "Name: count, dtype: int64\n",
      "Wrote filtered raw data to dataset/SLC6A2_Ki.csv\n",
      "\n",
      "SLC6A3 Ki: 3106 rows\n",
      "Dropped 867 rows with null units\n",
      "Dropped 3 rows with missing or 0/negative values\n",
      "Dropped 0 rows with weird units\n",
      "Row counts by units:\n",
      "standard_units\n",
      "nM    2230\n",
      "µM       6\n",
      "Name: count, dtype: int64\n",
      "Row counts by relation:\n",
      "standard_relation\n",
      "'='     1868\n",
      "'>'      319\n",
      "'<'        8\n",
      "'>='       2\n",
      "Name: count, dtype: int64\n",
      "Wrote filtered raw data to dataset/SLC6A3_Ki.csv\n",
      "\n",
      "SLC6A4 Ki: 4102 rows\n",
      "Dropped 913 rows with null units\n",
      "Dropped 5 rows with missing or 0/negative values\n",
      "Dropped 0 rows with weird units\n",
      "Row counts by units:\n",
      "standard_units\n",
      "nM    3184\n",
      "Name: count, dtype: int64\n",
      "Row counts by relation:\n",
      "standard_relation\n",
      "'='     2865\n",
      "'>'      264\n",
      "'<'       39\n",
      "'>='       2\n",
      "Name: count, dtype: int64\n",
      "Wrote filtered raw data to dataset/SLC6A4_Ki.csv\n"
     ]
    }
   ],
   "source": [
    "keep_cols = ['Molecule ChEMBL ID', 'Smiles', 'Standard Type', 'Standard Relation', 'Standard Value','Standard Units']\n",
    "new_cols = [col.lower().replace(' ', '_') for col in keep_cols]\n",
    "colmap = dict(zip( keep_cols, new_cols))\n",
    "filt_data = {}\n",
    "for endpoint in endpoints:\n",
    "    filt_data[endpoint] = {}\n",
    "    for target in targets:\n",
    "        raw_df = raw_data[endpoint][target]\n",
    "        print(f\"\\n{target} {endpoint}: {len(raw_df)} rows\")\n",
    "        filt_df = raw_df[keep_cols].copy().rename(columns=colmap)\n",
    "        filt_df = filt_df.dropna(axis=0, subset=['standard_units'])\n",
    "        print(f\"Dropped {len(raw_df) - len(filt_df)} rows with null units\")\n",
    "        nrows = len(filt_df)\n",
    "        filt_df = filt_df.dropna(axis=0, subset=['standard_value'])\n",
    "        filt_df = filt_df[filt_df.standard_value > 0.0].copy()\n",
    "        print(f\"Dropped {nrows - len(filt_df)} rows with missing or 0/negative values\")\n",
    "        nrows = len(filt_df)\n",
    "        filt_df = filt_df[filt_df.standard_units.isin(['µM', 'nM']) ].copy()\n",
    "        print(f\"Dropped {nrows - len(filt_df)} rows with weird units\")\n",
    "        print(f\"Row counts by units:\\n{filt_df.standard_units.value_counts()}\")\n",
    "        filt_df['standard_relation'] = filt_df.standard_relation.replace('nan', np.nan)\n",
    "        print(f\"Row counts by relation:\\n{filt_df.standard_relation.value_counts()}\")\n",
    "    \n",
    "        filt_data[endpoint][target] = filt_df\n",
    "        filt_file = f\"dataset/{target}_{endpoint}.csv\"\n",
    "        filt_df.to_csv(filt_file, index=False)\n",
    "        print(f\"Wrote filtered raw data to {filt_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ampl16_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
