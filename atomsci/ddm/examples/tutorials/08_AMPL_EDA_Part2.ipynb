{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ATOMScience-org/AMPL/blob/master/atomsci/ddm/examples/tutorials/08_AMPL_EDA_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFXkxwBu1C4W"
   },
   "source": [
    "# EDA Part two: visualizing results of hyperparameter search and predictions from best models (**read-only notebook**)\n",
    "**Please note that this template read-only notebook is designed for begineers and provides tips on how to identify good performing models. Our suggestion is use this notebook after you have carried out your HPO search and have access to several models. Please run this notebook on systems with large diskspace and dedicated resources (RAM, CPU)**\n",
    "\n",
    "# Scope of the tutorial\n",
    "* Visualize the hyper parameter search results\n",
    "* Extract the performance metrics of all the models\n",
    "* Examine the effect of RF Hyperparameters on the mode performance\n",
    "\n",
    "The tutorial will try to answer the following questions. Even if you didn't get good models for regression, try to create a few of each in order to perform the visualizations for your data.\n",
    "- Describe each visualization plots\n",
    "  - What's being plotted? \n",
    "  - What are X and Y axes? Add labels and titles to each plot for clarification\n",
    "    - And dont forget to add other information needed to understand the plot\n",
    "- Interpret what you see in each plot\n",
    "  - Hyperparameter searching:\n",
    "    - Do your models generalize well?\n",
    "    - Do you see overfitting? \n",
    "    - Do you think you chose the right hyperparameters\n",
    "    - If you trained more models, what additional hyperparameters would you try?\n",
    "    - What combination of features, model types and hyperparameters generally yields the best models?\n",
    "- Model predictions:\n",
    "  - Show your best random forest regression model (even if it's not great). How uncertain are your predictions?\n",
    "    - Interpret the uncertainty calibration curve. See the [AMPL paper](https://pubs.acs.org/doi/abs/10.1021/acs.jcim.9b01053) for more details.\n",
    "    - Choose your best models based on different metrics and compare: \n",
    "      - do you see any differences or similarities in model performance? \n",
    "      - What do you think the best metric is for your model?\n",
    "    - what limitations do you see in your model predictions?\n",
    "    - when you predict on new data (no ground truth available), can you identify whether your new data is within the applicability domain (https://www.nature.com/articles/s41467-020-17112-9) of the model?\n",
    "    - when you predict on data from a different target, how do your target predictions compare with the other target's ground truth? \n",
    "    - Are your two targets very similar or different when it comes to which compounds are most potent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZ70ierx3pq2"
   },
   "source": [
    "# Install AMPL packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNuv4Q5KFABw"
   },
   "outputs": [],
   "source": [
    "! pip install rdkit-pypi\n",
    "! pip install deepchem\n",
    "\n",
    "import deepchem\n",
    "# print(deepchem.__version__)\n",
    "! pip install umap\n",
    "! pip install -U --ignore-installed numba\n",
    "! pip install umap-learn\n",
    "! pip install molvs\n",
    "! pip install bravado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PrKWiSpMOLc"
   },
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "# get the Install AMPL_GPU_test.sh\n",
    "! wget 'https://raw.githubusercontent.com/ATOMScience-org/AMPL/master/atomsci/ddm/examples/tutorials/config/install_AMPL_GPU_test.sh'\n",
    "\n",
    "# run the script to install AMPL\n",
    "! chmod u+x install_AMPL_GPU_test.sh\n",
    "! ./install_AMPL_GPU_test.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InUQE4II1noi"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/ATOMScience-org/AMPL/master/atomsci/ddm/examples/tutorials/datasets/H1_std.csv >& /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTOwqhvR3xL3"
   },
   "source": [
    "# Load packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItqIxKjEigHL"
   },
   "outputs": [],
   "source": [
    "# We temporarily disable warnings for demonstration.\n",
    "# FutureWarnings and DeprecationWarnings are present from some of the AMPL \n",
    "# dependency modules.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import requests\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeN9kEMO2R9Z"
   },
   "outputs": [],
   "source": [
    "from atomsci.ddm.pipeline import model_pipeline as mp\n",
    "from atomsci.ddm.pipeline import parameter_parser as parse\n",
    "from atomsci.ddm.pipeline import perf_data\n",
    "from atomsci.ddm.pipeline import compare_models as cmp\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "pal = sns.color_palette()\n",
    "\n",
    "import pandas as pd\n",
    "import os, json, sys, glob, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NcMW4hWPuuG"
   },
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/ATOMScience-org/AMPL/master/atomsci/ddm/examples/tutorials/datasets/HTR3A_excape_curated.csv >& /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nciUW1Jvf8Ot"
   },
   "outputs": [],
   "source": [
    "h1 = pd.read_csv(\"HTR3A_excape_curated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RX5Nc73O6emX"
   },
   "outputs": [],
   "source": [
    "h1.Activity_Flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HC0yhEH7qkY6"
   },
   "outputs": [],
   "source": [
    "h1 = h1.rename(columns= {\"Activity_Flag\" : \"active\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5fFlTGpgA6s"
   },
   "outputs": [],
   "source": [
    "h1.active = h1.active.map(dict(A=1, N=0))\n",
    "h1 = h1.replace(to_replace=['A', 'N'], value=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgLXVkXO3wtU"
   },
   "outputs": [],
   "source": [
    "h1.active.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DL1mjHqvz2oR"
   },
   "outputs": [],
   "source": [
    "h1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jBdq35Q8Zhg"
   },
   "outputs": [],
   "source": [
    "h1[~h1.active.isna()]['PXC50'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Y2Ea2lYyyqH"
   },
   "outputs": [],
   "source": [
    "h1[h1['active'] == 1].PXC50.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAi8ITQIqy2F"
   },
   "outputs": [],
   "source": [
    "h1[h1['active'] == 0].PXC50.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3LK_JXoqDXq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwu9dkXJQcKP"
   },
   "outputs": [],
   "source": [
    "h1=h1[~h1.VALUE_NUM_mean.isna()]\n",
    "h1=h1[h1.VALUE_NUM_mean>2]\n",
    "h1.hist('VALUE_NUM_mean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coNNIQafgoSC"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xePRDvq4X00g"
   },
   "source": [
    "# Edit some AMPL functions to include xgboost parameters\n",
    "Just run this code once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UF_UUgmxUwYG"
   },
   "source": [
    "# compare_models   in get_summary_perf_tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "em35vSGMdw9l"
   },
   "outputs": [],
   "source": [
    "from atomsci.ddm.pipeline import predict_from_model as pfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yM0DNyKvX0kZ"
   },
   "outputs": [],
   "source": [
    "nan = np.float32('nan')\n",
    "def get_summary_perf_tables(collection_names=None, filter_dict={}, result_dir=None, prediction_type='regression', verbose=False):\n",
    "    \"\"\"\n",
    "    Load model parameters and performance metrics from model tracker for all models saved in the model tracker DB under\n",
    "    the given collection names (or result directory if Model tracker is not available) with the given prediction type. Tabulate the parameters and metrics including:\n",
    "        dataset (assay name, target, parameter, key, bucket)\n",
    "        dataset size (train/valid/test/total)\n",
    "        number of training folds\n",
    "        model type (NN or RF)\n",
    "        featurizer\n",
    "        transformation type\n",
    "        metrics: r2_score, mae_score and rms_score for regression, or ROC AUC for classification\n",
    "\n",
    "    result_dir: use result_dir when the model tracker is not available. Use a list format if you have multiple result direcotries.\n",
    "    \"\"\"\n",
    "    collection_list = []\n",
    "    model_uuid_list = []\n",
    "    time_built_list = []\n",
    "    prediction_type_list = []\n",
    "    model_type_list = []\n",
    "    dataset_key_list = []\n",
    "    bucket_list = []\n",
    "    param_list = []\n",
    "    featurizer_list = []\n",
    "    desc_type_list = []\n",
    "    transform_list = []\n",
    "    dset_size_list = []\n",
    "    splitter_list = []\n",
    "    split_strategy_list = []\n",
    "    split_uuid_list = []\n",
    "    rf_estimators_list = []\n",
    "    rf_max_features_list = []\n",
    "    rf_max_depth_list = []\n",
    "    best_epoch_list = []\n",
    "    max_epochs_list = []\n",
    "    learning_rate_list = []\n",
    "    layer_sizes_list = []\n",
    "    dropouts_list = []\n",
    "    xgb_gamma_list = []\n",
    "    xgb_learning_rate_list = []\n",
    "    umap_dim_list = []\n",
    "    umap_targ_wt_list = []\n",
    "    umap_neighbors_list = []\n",
    "    umap_min_dist_list = []\n",
    "    split_uuid_list=[]\n",
    "\n",
    "\n",
    "    if prediction_type == 'regression':\n",
    "        score_types = ['r2_score', 'mae_score', 'rms_score']\n",
    "    else:\n",
    "        # TODO: add more classification metrics later\n",
    "        score_types = ['roc_auc_score', 'prc_auc_score', 'accuracy_score', 'precision', 'recall_score', 'npv', 'matthews_cc', 'kappa','cross_entropy']\n",
    "\n",
    "    subsets = ['train', 'valid', 'test']\n",
    "    score_dict = {}\n",
    "    ncmpd_dict = {}\n",
    "    for subset in subsets:\n",
    "        score_dict[subset] = {}\n",
    "        for score_type in score_types:\n",
    "            score_dict[subset][score_type] = []\n",
    "        ncmpd_dict[subset] = []\n",
    "\n",
    "    metadata_list_dict = {}\n",
    "    if result_dir:\n",
    "        if isinstance(result_dir, str):\n",
    "            result_dir = [result_dir]\n",
    "        for rd in result_dir:\n",
    "            if rd not in metadata_list_dict:\n",
    "                metadata_list_dict[rd] = []\n",
    "            for dirpath, dirnames, filenames in os.walk(rd):\n",
    "                if \"model_metadata.json\" in filenames:\n",
    "                    with open(os.path.join(dirpath, 'model_metadata.json')) as f:\n",
    "                        metadata_dict = json.load(f)\n",
    "                    metadata_list_dict[rd].append(metadata_dict)\n",
    "\n",
    "    for ss in metadata_list_dict:\n",
    "        for i, metadata_dict in enumerate(metadata_list_dict[ss]):\n",
    "            if (i % 10 == 0) and verbose:\n",
    "                print('Processing collection %s model %d' % (ss, i))\n",
    "            # Check that model has metrics before we go on\n",
    "            if not 'training_metrics' in metadata_dict:\n",
    "                continue\n",
    "            collection_list.append(ss)\n",
    "            model_uuid = metadata_dict['model_uuid']\n",
    "            model_uuid_list.append(model_uuid)\n",
    "            time_built = metadata_dict['time_built']\n",
    "            time_built_list.append(time_built)\n",
    "\n",
    "            model_params = metadata_dict['model_parameters']\n",
    "            model_type = model_params['model_type']\n",
    "            model_type_list.append(model_type)\n",
    "            prediction_type_list.append(model_params['prediction_type'])\n",
    "            featurizer = model_params['featurizer']\n",
    "            featurizer_list.append(featurizer)\n",
    "            if 'descriptor_specific' in metadata_dict:\n",
    "                desc_type = metadata_dict['descriptor_specific']['descriptor_type']\n",
    "            elif featurizer in ['graphconv', 'ecfp']:\n",
    "                desc_type = featurizer\n",
    "            else:\n",
    "                desc_type = ''\n",
    "            desc_type_list.append(desc_type)\n",
    "            dataset_key = metadata_dict['training_dataset']['dataset_key']\n",
    "            bucket = metadata_dict['training_dataset']['bucket']\n",
    "            dataset_key_list.append(dataset_key)\n",
    "            bucket_list.append(bucket)\n",
    "            dset_metadata = metadata_dict['training_dataset']['dataset_metadata']\n",
    "            param = metadata_dict['training_dataset']['response_cols'][0]\n",
    "            param_list.append(param)\n",
    "            transform_type = metadata_dict['training_dataset']['feature_transform_type']\n",
    "            transform_list.append(transform_type)\n",
    "            split_params = metadata_dict['splitting_parameters']\n",
    "            splitter_list.append(split_params['splitter'])\n",
    "            split_uuid_list.append(split_params.get('split_uuid', ''))\n",
    "            split_strategy = split_params['split_strategy']\n",
    "            split_strategy_list.append(split_strategy)\n",
    "\n",
    "            if 'umap_specific' in metadata_dict:\n",
    "                umap_params = metadata_dict['umap_specific']\n",
    "                umap_dim_list.append(umap_params['umap_dim'])\n",
    "                umap_targ_wt_list.append(umap_params['umap_targ_wt'])\n",
    "                umap_neighbors_list.append(umap_params['umap_neighbors'])\n",
    "                umap_min_dist_list.append(umap_params['umap_min_dist'])\n",
    "            else:\n",
    "                umap_dim_list.append(nan)\n",
    "                umap_targ_wt_list.append(nan)\n",
    "                umap_neighbors_list.append(nan)\n",
    "                umap_min_dist_list.append(nan)\n",
    "\n",
    "            if model_type == 'NN':\n",
    "                nn_params = metadata_dict['nn_specific']\n",
    "                max_epochs_list.append(nn_params['max_epochs'])\n",
    "                best_epoch_list.append(nn_params['best_epoch'])\n",
    "                learning_rate_list.append(nn_params['learning_rate'])\n",
    "                layer_sizes_list.append(','.join(['%d' % s for s in nn_params['layer_sizes']]))\n",
    "                dropouts_list.append(','.join(['%.2f' % d for d in nn_params['dropouts']]))\n",
    "                rf_estimators_list.append(nan)\n",
    "                rf_max_features_list.append(nan)\n",
    "                rf_max_depth_list.append(nan)\n",
    "                xgb_gamma_list.append(nan)\n",
    "                xgb_learning_rate_list.append(nan)\n",
    "            elif model_type == 'RF':\n",
    "                rf_params = metadata_dict['rf_specific']\n",
    "                rf_estimators_list.append(rf_params['rf_estimators'])\n",
    "                rf_max_features_list.append(rf_params['rf_max_features'])\n",
    "                rf_max_depth_list.append(rf_params['rf_max_depth'])\n",
    "                max_epochs_list.append(nan)\n",
    "                best_epoch_list.append(nan)\n",
    "                learning_rate_list.append(nan)\n",
    "                layer_sizes_list.append(nan)\n",
    "                dropouts_list.append(nan)\n",
    "                xgb_gamma_list.append(nan)\n",
    "                xgb_learning_rate_list.append(nan)\n",
    "            elif model_type == 'xgboost':\n",
    "                # TODO: Add xgboost parameters\n",
    "                xg_params = metadata_dict['xgb_specific']\n",
    "                xgb_gamma_list.append(xg_params['xgb_gamma'])\n",
    "                xgb_learning_rate_list.append(xg_params['xgb_learning_rate'])\n",
    "                max_epochs_list.append(nan)\n",
    "                best_epoch_list.append(nan)\n",
    "                learning_rate_list.append(nan)\n",
    "                layer_sizes_list.append(nan)\n",
    "                dropouts_list.append(nan)\n",
    "                rf_estimators_list.append(nan)\n",
    "                rf_max_features_list.append(nan)\n",
    "                rf_max_depth_list.append(nan)\n",
    "            else:\n",
    "                raise Exception('Unexpected model type %s' % model_type)\n",
    "\n",
    "            # Get model metrics for this model\n",
    "            metrics_dicts = metadata_dict['training_metrics']\n",
    "            #print(\"Got %d metrics dicts for model %s\" % (len(metrics_dicts), model_uuid))\n",
    "            subset_metrics = {}\n",
    "            for metrics_dict in metrics_dicts:\n",
    "                if metrics_dict['label'] == 'best':\n",
    "                    subset = metrics_dict['subset']\n",
    "                    subset_metrics[subset] = metrics_dict['prediction_results']\n",
    "            if split_strategy == 'k_fold_cv':\n",
    "                dset_size = subset_metrics['train']['num_compounds'] + subset_metrics['test']['num_compounds']\n",
    "            else:\n",
    "                dset_size = subset_metrics['train']['num_compounds'] + subset_metrics['valid']['num_compounds'] + subset_metrics['test']['num_compounds']\n",
    "            for subset in subsets:\n",
    "                subset_size = subset_metrics[subset]['num_compounds']\n",
    "                for score_type in score_types:\n",
    "                    try:\n",
    "                        score = subset_metrics[subset][score_type]\n",
    "                    except KeyError:\n",
    "                        score = float('nan')\n",
    "                    score_dict[subset][score_type].append(score)\n",
    "                ncmpd_dict[subset].append(subset_size)\n",
    "            dset_size_list.append(dset_size)\n",
    "\n",
    "    col_dict = dict(\n",
    "                    collection=collection_list,\n",
    "                    model_uuid=model_uuid_list,\n",
    "                    time_built=time_built_list,\n",
    "                    prediction_type=prediction_type_list,\n",
    "                    model_type=model_type_list,\n",
    "                    featurizer=featurizer_list,\n",
    "                    features=desc_type_list,\n",
    "                    transformer=transform_list,\n",
    "                    splitter=splitter_list,\n",
    "                    split_strategy=split_strategy_list,\n",
    "                    split_uuid=split_uuid_list,\n",
    "                    umap_dim=umap_dim_list,\n",
    "                    umap_targ_wt=umap_targ_wt_list,\n",
    "                    umap_neighbors=umap_neighbors_list,\n",
    "                    umap_min_dist=umap_min_dist_list,\n",
    "                    layer_sizes=layer_sizes_list,\n",
    "                    dropouts=dropouts_list,\n",
    "                    learning_rate=learning_rate_list,\n",
    "                    best_epoch=best_epoch_list,\n",
    "                    max_epochs=max_epochs_list,\n",
    "                    rf_estimators=rf_estimators_list,\n",
    "                    rf_max_features=rf_max_features_list,\n",
    "                    rf_max_depth=rf_max_depth_list,\n",
    "                    xgb_gamma = xgb_gamma_list,\n",
    "                    xgb_learning_rate = xgb_learning_rate_list,\n",
    "                    dataset_bucket=bucket_list,\n",
    "                    dataset_key=dataset_key_list,\n",
    "                    dataset_size=dset_size_list,\n",
    "                    parameter=param_list\n",
    "                    )\n",
    "\n",
    "    perf_df = pd.DataFrame(col_dict)\n",
    "    for subset in subsets:\n",
    "        ncmpds_col = '%s_size' % subset\n",
    "        perf_df[ncmpds_col] = ncmpd_dict[subset]\n",
    "        for score_type in score_types:\n",
    "            metric_col = '%s_%s' % (subset, score_type)\n",
    "            perf_df[metric_col] = score_dict[subset][score_type]\n",
    "\n",
    "    return perf_df\n",
    "\n",
    "from atomsci.ddm.pipeline import predict_from_model as pfm\n",
    "\n",
    "def predict_from_model_file(model_path, input_df, id_col='compound_id', smiles_col='rdkit_smiles',\n",
    "                     response_col=None, is_featurized=False, dont_standardize=False):\n",
    "    \"\"\"\n",
    "    Loads a pretrained model from a model tarball file and runs predictions on compounds in an input\n",
    "    data frame.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): File path of the model tarball file.\n",
    "\n",
    "        input_df (DataFrame): Input data to run predictions on; must at minimum contain SMILES strings.\n",
    "\n",
    "        id_col (str): Name of the column containing compound IDs. If none is provided, sequential IDs will be\n",
    "        generated.\n",
    "\n",
    "        smiles_col (str): Name of the column containing SMILES strings; required.\n",
    "\n",
    "        response_col (str): Name of an optional column containing actual response values; if it is provided, \n",
    "        the actual values will be included in the returned data frame to make it easier for you to assess performance.\n",
    "\n",
    "        dont_standardize (bool): By default, SMILES strings are salt-stripped and standardized using RDKit; \n",
    "        if you have already done this, or don't want them to be standardized, set dont_standardize to True.\n",
    "\n",
    "    Return: \n",
    "        A data frame with compound IDs, SMILES strings and predicted response values. Actual response values\n",
    "        will be included if response_col is provided. Standard prediction error estimates will be included\n",
    "        if the model was trained with uncertainty=True. Note that the predicted and actual response\n",
    "        columns will be labeled according to the response_col setting in the original training data,\n",
    "        not the response_col passed to this function; e.g. if the original model response_col was 'pIC50',\n",
    "        the returned data frame will contain columns 'pIC50_actual', 'pIC50_pred' and 'pIC50_std'.\n",
    "    \"\"\"\n",
    "\n",
    "    input_df, pred_params = pfm._prepare_input_data(input_df, id_col, smiles_col, response_col, dont_standardize)\n",
    "\n",
    "    has_responses = ('response_cols' in pred_params)\n",
    "    pred_params = parse.wrapper(pred_params)\n",
    "\n",
    "    pipe = mp.create_prediction_pipeline_from_file(pred_params, reload_dir=None, model_path=model_path)\n",
    "    if pipe.params.model_type == 'xgboost':\n",
    "        pipe.params.uncertainty = False\n",
    "    pred_df = pipe.predict_full_dataset(input_df, contains_responses=has_responses, is_featurized=is_featurized,\n",
    "                                        dset_params=pred_params)\n",
    "    pred_df = pred_df.sort_values(by=id_col)\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHjYDaTNBYjQ"
   },
   "source": [
    "# Visualize hyper parameter search\n",
    "- you can use regression or classification models for this, just choose a different metric for the y-axis\n",
    "- box plots work well if you did a grid search, scatter plots better if you did a HPO optimization\n",
    "- LOTS of parameters to look at, think about questions you have for the data:\n",
    "  - how do train, valid and test metrics look?\n",
    "  - which features are best for modeling the data?\n",
    "  - which hp's are the best?\n",
    "  - which models are the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UY2GIhSTa4uL"
   },
   "source": [
    "#### Get a table of performance metrics of all models in your directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmje8AyH-0UB"
   },
   "outputs": [],
   "source": [
    "# slow the first time after connecting your google drive\n",
    "result_dir = '/content/HTR3A_models'\n",
    "perf_df = cmp.get_summary_perf_tables(collection_names=None, filter_dict={}, \n",
    "                                  prediction_type = 'classification', \n",
    "                                  result_dir=result_dir, \n",
    "                                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrSQ4Y_I_VDr"
   },
   "outputs": [],
   "source": [
    "perf_df = perf_df[perf_df.rf_estimators!=500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caZqAaigSJWD"
   },
   "outputs": [],
   "source": [
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntKBZyXv-8kS"
   },
   "outputs": [],
   "source": [
    "perf_df = perf_df[perf_df.prediction_type=='classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSDa2HTH6wbD"
   },
   "outputs": [],
   "source": [
    "\n",
    "perf_df.sort_values(by=\"valid_roc_auc_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaZlpJQJSffk"
   },
   "outputs": [],
   "source": [
    "cmp.perf_df.groupby(by=['model_type', 'features']).count()[['model_uuid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvvLRaxhbHzJ"
   },
   "source": [
    "#### Examine R2 scores from train, valid and test sets\n",
    "- examine MAE or RMS scores instead. Do you see differences?\n",
    "- Play around with hues from different hyperparameters. Do you see any trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_uRvu0BI-D4"
   },
   "outputs": [],
   "source": [
    "# what are the scores like for train, valid and test sets?\n",
    "\n",
    "scoretype='roc_auc_score'\n",
    "subset='valid'\n",
    "winnertype= f'{subset}_{scoretype}'\n",
    "plot_df=perf_df[[f\"train_{scoretype}\",f\"valid_{scoretype}\",f\"test_{scoretype}\"]]\n",
    "# turn off sorting if you have a ton of models.. slow\n",
    "plot_df=plot_df.sort_values(f\"valid_{scoretype}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize=(40,10))\n",
    "sns.kdeplot(perf_df[f'train_{scoretype}'], label=\"train\",ax=ax[0])\n",
    "sns.kdeplot(perf_df[f'valid_{scoretype}'], label=\"valid\",ax=ax[0])\n",
    "sns.kdeplot(perf_df[f'test_{scoretype}'], label=\"test\",ax=ax[0])\n",
    "ax[0].set_xlabel(f'{scoretype}')\n",
    "\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "plot_df = perf_df[perf_df.model_type==\"RF\"]\n",
    "huefeat = 'rf_estimators'\n",
    "plot_df=plot_df[[f\"train_{scoretype}\",f\"valid_{scoretype}\",f\"test_{scoretype}\", huefeat, 'model_uuid']]\n",
    "plot_df=plot_df.sort_values(f\"valid_{scoretype}\")\n",
    "plot_df=plot_df.melt(id_vars=['model_uuid',huefeat])\n",
    "sns.lineplot(data=plot_df, x='variable', y='value', units ='model_uuid', estimator=None, hue=huefeat, legend='brief', ax = ax[1]);\n",
    "ax[1].set_ylim(perf_df[f'test_{scoretype}'].min()-.1,1)\n",
    "ax[1].set_title('RF')\n",
    "\n",
    "plot_df = perf_df[perf_df.model_type==\"NN\"]\n",
    "huefeat = 'learning_rate'\n",
    "plot_df=plot_df[[f\"train_{scoretype}\",f\"valid_{scoretype}\",f\"test_{scoretype}\", huefeat, 'model_uuid']]\n",
    "plot_df=plot_df.sort_values(f\"valid_{scoretype}\")\n",
    "plot_df=plot_df.melt(id_vars=['model_uuid',huefeat])\n",
    "sns.lineplot(data=plot_df, x='variable', y='value', units ='model_uuid', estimator=None, hue=huefeat, legend='brief', ax = ax[2]);\n",
    "ax[2].set_ylim(perf_df[f'test_{scoretype}'].min()-.1,1)\n",
    "ax[2].set_title('NN')\n",
    "\n",
    "plot_df = perf_df[perf_df.model_type==\"xgboost\"]\n",
    "huefeat = 'xgb_learning_rate'\n",
    "plot_df=plot_df[[f\"train_{scoretype}\",f\"valid_{scoretype}\",f\"test_{scoretype}\", huefeat, 'model_uuid']]\n",
    "plot_df=plot_df.sort_values(f\"valid_{scoretype}\")\n",
    "plot_df=plot_df.melt(id_vars=['model_uuid',huefeat])\n",
    "sns.lineplot(data=plot_df, x='variable', y='value', units ='model_uuid', estimator=None, hue=huefeat, legend='brief', ax = ax[3]);\n",
    "ax[3].set_ylim(perf_df[f'test_{scoretype}'].min()-.1,1)\n",
    "ax[3].set_title('xgboost')\n",
    "\n",
    "fig.suptitle(f\"{scoretype}s for HTR3A regression models\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yHDxIS0c9b-"
   },
   "source": [
    "#### Examine R2 scores for each feature set\n",
    "- what do you think of the variability among scores for different model types? Is it different for MAE or RMS scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUQXBtQPZj8p"
   },
   "outputs": [],
   "source": [
    "# which feature set works best for each model type?\n",
    "\n",
    "fig,ax = plt.subplots(1,3,sharey=True, figsize=(26,8))\n",
    "plot_df = perf_df[perf_df.model_type=='RF']\n",
    "sns.boxplot(data=plot_df, x=\"features\", y=f\"valid_{scoretype}\", width = 0.8, ax=ax[0]);\n",
    "# plot_df = perf_df[perf_df.model_type=='NN']\n",
    "# sns.boxplot(data=plot_df, x=\"features\", y=f\"valid_{scoretype}\", width = 0.8, ax=ax[1]);\n",
    "# plot_df = perf_df[perf_df.model_type=='xgboost']\n",
    "# sns.boxplot(data=plot_df, x=\"features\", y=f\"valid_{scoretype}\", width = 0.8, ax=ax[2]);\n",
    "ax[0].set_title(\"RF\");\n",
    "ax[1].set_title(\"NN\");\n",
    "ax[2].set_title(\"XG\");\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnvptW5T0mKK"
   },
   "source": [
    "#### Examine the effect of RF hyperparameters on model performance\n",
    "- any major differences between feature sets?\n",
    "- did you capture the right range of HPs or do you need to expand / zero in on a particular range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bVXltSu6z0f"
   },
   "outputs": [],
   "source": [
    "modtype = 'RF'\n",
    "feat1 = 'rf_estimators'\n",
    "feat2 = 'rf_max_depth'\n",
    "feat3 = 'rf_max_features'\n",
    "sub_df = perf_df[perf_df.model_type==modtype]\n",
    "\n",
    "fig, ax = plt.subplots(3,3,sharey=True, figsize=(26,18))\n",
    "plot_df=sub_df[sub_df.features=='ecfp']\n",
    "sns.boxplot(data=plot_df, x=feat1, y=f\"valid_{scoretype}\", ax=ax[0,0])\n",
    "sns.boxplot(data=plot_df, x=feat2, y=f\"valid_{scoretype}\", ax=ax[0,1])\n",
    "ax[0,1].set_title(f\"{modtype} - {plot_df.features.iloc[0]}\")\n",
    "sns.boxplot(data=plot_df, x=feat3, y=f\"valid_{scoretype}\", ax=ax[0,2])\n",
    "\n",
    "plot_df=sub_df[sub_df.features=='mordred_filtered']\n",
    "sns.boxplot(data=plot_df, x=feat1, y=f\"valid_{scoretype}\", ax=ax[1,0])\n",
    "sns.boxplot(data=plot_df, x=feat2, y=f\"valid_{scoretype}\", ax=ax[1,1])\n",
    "ax[1,1].set_title(f\"{modtype} - {plot_df.features.iloc[0]}\")\n",
    "sns.boxplot(data=plot_df, x=feat3, y=f\"valid_{scoretype}\", ax=ax[1,2])\n",
    "\n",
    "plot_df=sub_df[sub_df.features=='rdkit_raw']\n",
    "sns.boxplot(data=plot_df, x=feat1, y=f\"valid_{scoretype}\", ax=ax[2,0])\n",
    "sns.boxplot(data=plot_df, x=feat2, y=f\"valid_{scoretype}\", ax=ax[2,1])\n",
    "ax[2,1].set_title(f\"{modtype} - {plot_df.features.iloc[0]}\")\n",
    "sns.boxplot(data=plot_df, x=feat3, y=f\"valid_{scoretype}\", ax=ax[2,2])\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Yl3HitD0tQ5"
   },
   "source": [
    "#### Examine NN hyperparameters\n",
    "- are training or test sets different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy9I-HiWKfIG"
   },
   "outputs": [],
   "source": [
    "modtype = 'NN'\n",
    "feat1 = 'dropouts'\n",
    "feat2 = 'learning_rate'\n",
    "feat3 = 'layer_sizes'\n",
    "sub_df = perf_df[perf_df.model_type==modtype]\n",
    "\n",
    "fig, ax = plt.subplots(3,3,sharey=True,figsize=(26,18))\n",
    "plot_df=sub_df[sub_df.features=='ecfp']\n",
    "sns.boxplot(data=plot_df, x=feat1, y=\"valid_r2_score\", ax=ax[0,0])\n",
    "sns.boxplot(data=plot_df, x=feat2, y=\"valid_r2_score\", ax=ax[0,1])\n",
    "ax[0,1].set_title(f\"{modtype} - {plot_df.features.iloc[0]}\")\n",
    "sns.boxplot(data=plot_df, x=feat3, y=\"valid_r2_score\", ax=ax[0,2])\n",
    "\n",
    "plot_df=sub_df[sub_df.features=='mordred_filtered']\n",
    "sns.boxplot(data=plot_df, x=feat1, y=\"valid_r2_score\", ax=ax[1,0])\n",
    "sns.boxplot(data=plot_df, x=feat2, y=\"valid_r2_score\", ax=ax[1,1])\n",
    "ax[1,1].set_title(f\"{modtype} - {plot_df.features.iloc[0]}\")\n",
    "sns.boxplot(data=plot_df, x=feat3, y=\"valid_r2_score\", ax=ax[1,2])\n",
    "\n",
    "plot_df=sub_df[sub_df.features=='rdkit_raw']\n",
    "sns.boxplot(data=plot_df, x=feat1, y=\"valid_r2_score\", ax=ax[2,0])\n",
    "sns.boxplot(data=plot_df, x=feat2, y=\"valid_r2_score\", ax=ax[2,1]); ax[2,1].tick_params(axis='x', rotation=45);\n",
    "ax[2,1].set_title(f\"{modtype} - {plot_df.features.iloc[0]}\")\n",
    "sns.boxplot(data=plot_df, x=feat3, y=\"valid_r2_score\", ax=ax[2,2])\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjOQkIQj02OD"
   },
   "source": [
    "#### Examine XGBoost hyperparameters\n",
    "- what is the third graph?\n",
    "- how do R2 vs RMS scores look?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd9d7RsGOrkr"
   },
   "outputs": [],
   "source": [
    "modtype = 'xgboost'\n",
    "feat1 = 'xgb_gamma'\n",
    "feat2 = 'xgb_learning_rate'\n",
    "feat3 = 'valid_mae_score'\n",
    "sub_df = perf_df[perf_df.model_type==modtype]\n",
    "\n",
    "fig, ax = plt.subplots(3,3,sharey=True, figsize=(26,18))\n",
    "plot_df=sub_df[sub_df.features=='ecfp']\n",
    "sns.boxplot(data=plot_df, x=feat1, y=\"valid_r2_score\", ax=ax[0,0])\n",
    "sns.boxplot(data=plot_df, x=feat2, y=\"valid_r2_score\", ax=ax[0,1])\n",
    "ax[0,1].set_title(f\"{modtype} - {plot_df.features.iloc[0]}\")\n",
    "sns.scatterplot(data=plot_df, x=feat3, y=\"valid_r2_score\", ax=ax[0,2])\n",
    "\n",
    "plot_df=sub_df[sub_df.features=='mordred_filtered']\n",
    "sns.boxplot(data=plot_df, x=feat1, y=\"valid_r2_score\", ax=ax[1,0])\n",
    "sns.boxplot(data=plot_df, x=feat2, y=\"valid_r2_score\", ax=ax[1,1])\n",
    "ax[1,1].set_title(f\"{modtype} - {plot_df.features.iloc[0]}\")\n",
    "sns.scatterplot(data=plot_df, x=feat3, y=\"valid_r2_score\", ax=ax[1,2])\n",
    "\n",
    "plot_df=sub_df[sub_df.features=='rdkit_raw']\n",
    "sns.boxplot(data=plot_df, x=feat1, y=\"valid_r2_score\", ax=ax[2,0])\n",
    "sns.boxplot(data=plot_df, x=feat2, y=\"valid_r2_score\", ax=ax[2,1]); ax[2,1].tick_params(axis='x', rotation=45);\n",
    "ax[2,1].set_title(f\"{modtype} - {plot_df.features.iloc[0]}\")\n",
    "sns.scatterplot(data=plot_df, x=feat3, y=\"valid_r2_score\", ax=ax[2,2])\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju-M1g4JexDu"
   },
   "source": [
    "# Choose best model and examine predictions (regression models)\n",
    "Metrics for regression models:\n",
    "- RMSE\n",
    "- MAE\n",
    "- R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PfY59IYq6-n"
   },
   "source": [
    "#### select models and generate predictions\n",
    "- predict on the same dataset as the model was trained on first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kB5I0AU7ewHV"
   },
   "outputs": [],
   "source": [
    "# best models per metric\n",
    "top_r2_model = perf_df[perf_df.valid_r2_score==perf_df.valid_r2_score.max()]    # maximize pearson correlation\n",
    "top_rms_model = perf_df[perf_df.valid_rms_score==perf_df.valid_rms_score.min()] # minimize root mean squared error\n",
    "top_mae_model = perf_df[perf_df.valid_mae_score==perf_df.valid_mae_score.min()] # minimize mean absolute error\n",
    "display(top_r2_model, top_rms_model, top_mae_model)\n",
    "# note: only two different model_uuids here; note featurizer & featurizer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPZC5056gw-B"
   },
   "outputs": [],
   "source": [
    "from atomsci.ddm.pipeline import predict_from_model as pfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yj6F7WF5iEQ2"
   },
   "outputs": [],
   "source": [
    "# create strings that are paths to the best models based on their model_uuids\n",
    "rms_model_path = top_rms_model.collection.values[0]+'/'+top_rms_model.dataset_key.values[0].split('/')[-1].strip('.csv')+'_model_'+top_rms_model.model_uuid.values[0]+'.tar.gz'\n",
    "mae_model_path = top_mae_model.collection.values[0]+'/'+top_mae_model.dataset_key.values[0].split('/')[-1].strip('.csv')+'_model_'+top_mae_model.model_uuid.values[0]+'.tar.gz'\n",
    "split_path = f'/content/drive/MyDrive/Columbia_E4511/HTR3A_curated_train_valid_test_scaffold_{top_rms_model.split_uuid.values[0]}.csv'\n",
    "split_df=pd.read_csv(split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuPgERoIIQ-P"
   },
   "outputs": [],
   "source": [
    "# check what features the models used - get paths to the mordred or rdkit features as needed\n",
    "mordred_input_df = pd.read_csv('/content/drive/MyDrive/Columbia_E4511/scaled_descriptors/HTR3A_curated_with_mordred_filtered_descriptors.csv')\n",
    "mordred_input_df = mordred_input_df[~mordred_input_df.VALUE_NUM_mean.isna()]\n",
    "mordred_input_df = mordred_input_df[mordred_input_df.VALUE_NUM_mean>2]\n",
    "ecfp_input_df = h1\n",
    "display(mordred_input_df.head(), ecfp_input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOKBu907hlTs"
   },
   "outputs": [],
   "source": [
    "# predict using your best models\n",
    "# if the models use ECFP (or graphconv), is_featurized = False and the input df is equivalent to the original data df\n",
    "# if the models use rdkit or mordred, is_featurized = True and the input df is the featurized df from the scaled descriptors folder\n",
    "# if you use rdkit or mordred and leave featurized=False then the smiles will be re-featurized and it can take a very long time\n",
    "rms_pred = predict_from_model_file(model_path= rms_model_path, input_df=ecfp_input_df, id_col='compound_id', smiles_col = 'base_rdkit_smiles', \n",
    "                            response_col = 'VALUE_NUM_mean', is_featurized = False, dont_standardize=True)\n",
    "mae_pred = predict_from_model_file(model_path= mae_model_path, input_df=ecfp_input_df, id_col='compound_id', smiles_col = 'base_rdkit_smiles', \n",
    "                            response_col = 'VALUE_NUM_mean', is_featurized = False, dont_standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9_jqieBo5oB"
   },
   "outputs": [],
   "source": [
    "# merge with the split df so you know which molecule was in each subset (or if k-fold x-val, training(train+valid) and test subsets only)\n",
    "# create 'prediction_error' column as diff btw real and pred vals\n",
    "rms_pred = pd.merge(rms_pred, split_df, left_on='compound_id', right_on='cmpd_id')\n",
    "rms_pred['pred_err'] = abs(rms_pred.VALUE_NUM_mean_actual - rms_pred.VALUE_NUM_mean_pred)\n",
    "rms_pred=rms_pred.sort_values('pred_err')\n",
    "mae_pred = pd.merge(mae_pred, split_df, left_on='compound_id', right_on='cmpd_id')\n",
    "mae_pred['pred_err'] = abs(mae_pred.VALUE_NUM_mean_actual - mae_pred.VALUE_NUM_mean_pred)\n",
    "mae_pred=mae_pred.sort_values('pred_err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "975fah3_jvis"
   },
   "outputs": [],
   "source": [
    "display(rms_pred.head(), mae_pred.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FDCahYJisUV"
   },
   "source": [
    "#### Plot predicted vs actual values for each model\n",
    "- What do you notice about the predictions? Do they cut off at a certain point?\n",
    "- What do you notice about train/valid/test splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iveiJHGJklyg"
   },
   "outputs": [],
   "source": [
    "response_col = 'VALUE_NUM_mean'\n",
    "fig, ax = plt.subplots(2,3,sharex=True, figsize=(26,16))\n",
    "\n",
    "sns.scatterplot(data=rms_pred, x=f'{response_col}_actual', y=f'{response_col}_pred', ax=ax[0,0], hue = 'subset')\n",
    "sns.scatterplot(data=mae_pred, x=f'{response_col}_actual', y=f'{response_col}_pred', ax=ax[0,1], hue = 'subset', legend=False)\n",
    "sns.scatterplot(x=rms_pred[f'{response_col}_pred'], y=mae_pred[f'{response_col}_pred'], ax=ax[0,2], color=pal[3])\n",
    "ax[0,2].set_ylabel('MAE')\n",
    "\n",
    "ax[0,0].plot([2, 11], [2, 11], linewidth=2, color='lightgrey', zorder=0)\n",
    "ax[0,1].plot([2, 11], [2, 11], linewidth=2, color='lightgrey', zorder=0)\n",
    "ax[0,2].plot([2, 11], [2, 11], linewidth=2, color='lightgrey', zorder=0)\n",
    "ax[1,2].plot([2, 11], [2, 11], linewidth=2, color='lightgrey', zorder=0)\n",
    "\n",
    "ax[0,0].set_title('Top Model 1: R2/RMS')\n",
    "ax[0,1].set_title('Top Model 2: MAE')\n",
    "ax[0,2].set_title('R2/RMS vs MAE predictions')\n",
    "\n",
    "sns.distplot(x=rms_pred[f'{response_col}_pred'],ax=ax[1,0], axlabel = 'R2/RMS Predictions');\n",
    "sns.distplot(x=mae_pred[f'{response_col}_pred'],ax=ax[1,1], axlabel = 'MAE Predictions');\n",
    "sns.kdeplot(x=rms_pred[f'{response_col}_pred'], y=mae_pred[f'{response_col}_pred'], ax=ax[1,2])\n",
    "ax[1,2].set_ylabel('MAE')\n",
    "ax[1,2].set_xlabel('R2/RMS')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQHu1chwlQfc"
   },
   "source": [
    "#### Look at uncertainty of predictions\n",
    "- for this one, choose an RF model you trained with uncertainty=True\n",
    "- Does uncertainty correlate with anything? such as magnitude of prediction, or prediction error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZTnkuRcr88h"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxq2ubyGlYMH"
   },
   "outputs": [],
   "source": [
    "pred_df=mae_pred\n",
    "hi = 11; lo=2\n",
    "\n",
    "fig, ax = plt.subplots(1,3, sharex=True, sharey=True, figsize=(26,8))\n",
    "sns.scatterplot(x=f'{response_col}_actual', y=f'{response_col}_pred', hue=f'{response_col}_std', data=pred_df[pred_df['subset']==\"train\"], legend=False, ax=ax[0])\n",
    "ax[0].set_title(\"Train\")\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[0].set_ylabel(f\"Predicted values\")\n",
    "\n",
    "sns.scatterplot(x=f'{response_col}_actual', y=f'{response_col}_pred', hue=f'{response_col}_std', data=pred_df[pred_df['subset']==\"valid\"], legend=False, ax=ax[1])\n",
    "ax[1].set_title(\"Valid\")\n",
    "ax[1].set_xlabel(f\"Actual values\")\n",
    "\n",
    "sns.scatterplot(x=f'{response_col}_actual', y=f'{response_col}_pred', hue=f'{response_col}_std', data=pred_df[pred_df['subset']==\"test\"], legend=False, ax=ax[2])\n",
    "ax[2].set_title(\"Test\");\n",
    "ax[2].set_xlabel(\"\")\n",
    "\n",
    "plt.xlim(lo,hi)\n",
    "plt.ylim(1,math.ceil(pred_df[f'{response_col}_pred'].max()))\n",
    "plt.ylim(lo,hi)\n",
    "\n",
    "ax[0].plot([lo, hi], [lo, hi], linewidth=2, color='lightgrey', zorder=0)\n",
    "ax[1].plot([lo, hi], [lo, hi], linewidth=2, color='lightgrey', zorder=0)\n",
    "ax[2].plot([lo, hi], [lo, hi], linewidth=2, color='lightgrey', zorder=0)\n",
    "\n",
    "# color bar\n",
    "norm = plt.Normalize(pred_df[f'{response_col}_std'].min(), pred_df[f'{response_col}_std'].max())\n",
    "sm = plt.cm.ScalarMappable(cmap=sns.cubehelix_palette(as_cmap=True), norm=norm)\n",
    "ax[2].figure.colorbar(sm)\n",
    "\n",
    "fig.suptitle(f\"Best MAE RF model shaded by uncertainty\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7Os0X48sMM0"
   },
   "outputs": [],
   "source": [
    "subset='test'\n",
    "pred_df=mae_pred[mae_pred.subset==subset]\n",
    "fig, ax = plt.subplots(1,2,figsize=(18,7))\n",
    "sns.scatterplot(x='pred_err', y=f'{response_col}_std',  data=pred_df, ax=ax[0])\n",
    "sns.scatterplot(x=f'{response_col}_pred', y=f'{response_col}_std',  data=pred_df, ax=ax[1]);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N50GdTh5mPJC"
   },
   "source": [
    "#### Uncertainty calibration curve\n",
    "Extra credit: interpret this plot according to writeup in ampl paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lHApE3vywPu"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "pred_df=mae_pred\n",
    "sub_df=pred_df[pred_df['subset']==\"test\"]\n",
    "# divide test set into equal bins based on uncertainty values\n",
    "qbins=pd.qcut(sub_df[f'{response_col}_std'], q=12, duplicates='drop')\n",
    "qbins=pd.DataFrame({'intervals': qbins.cat.categories, 'left': qbins.cat.categories.left, 'right': qbins.cat.categories.right})\n",
    "qbins=pd.concat([qbins, pd.DataFrame({'intervals': [np.nan], 'left': [qbins.right.max()], 'right': [np.nan]})])\n",
    "# for each bin, calculate the average + stdev of prediction errors\n",
    "bin_means, bin_edges, binnumber = stats.binned_statistic(sub_df[f'{response_col}_std'], sub_df.pred_err , 'mean', bins=qbins.left)\n",
    "bin_stds, bin_edges, binnumber = stats.binned_statistic(sub_df[f'{response_col}_std'], sub_df.pred_err , 'std', bins=qbins.left)\n",
    "bin_counts, bin_edges, binnumber = stats.binned_statistic(sub_df[f'{response_col}_std'], sub_df.pred_err ,'count', bins=qbins.left)\n",
    "\n",
    "x = pd.Series(np.around(bin_edges[1:],2).astype(str))\n",
    "y = bin_means\n",
    "e = bin_stds\n",
    "\n",
    "xlbs=x+', n='+pd.Series(bin_counts.astype(int).astype(str))\n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(10, 8))\n",
    "ax1.errorbar(xlbs, y, e, linestyle='None', marker='o')\n",
    "ax1.set_xlabel('Uncertainty threshold (Test set)')\n",
    "ax1.set_ylabel('Prediction error')\n",
    "plt.xticks(xlbs, rotation=60, ha='right')\n",
    "#plt.ylim(-.5,2)\n",
    "fig.suptitle(f\"MAE RF model uncertainty calibration curve\")\n",
    "\n",
    "print(bin_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ywg5eTpxm7aJ"
   },
   "source": [
    "#### Look at prediction error and uncertainty compared to tanimoto distance from training set\n",
    "- which do you think correlates better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvngB75TyBsq"
   },
   "outputs": [],
   "source": [
    "from atomsci.ddm.pipeline import chem_diversity as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-sCftMcroTo"
   },
   "outputs": [],
   "source": [
    "pred_df=mae_pred\n",
    "test = pred_df[pred_df.subset=='test']\n",
    "train = pred_df[pred_df.subset=='train']\n",
    "# For each compound in the test set, (or new prediction set) find the nearest neighbor in the training set and calculate the distance to that neighbor\n",
    "test['nnd_train']=cd.calc_dist_smiles('ecfp', 'tanimoto', test.base_rdkit_smiles, train.base_rdkit_smiles, calc_type='nearest', num_nearest=1)\n",
    "fig, ax = plt.subplots(1,2,figsize=(18,10))\n",
    "sns.scatterplot(x='nnd_train', y='pred_err', data=test, legend=False, ax=ax[0])\n",
    "ax[0].set_xlabel(\"Tanimoto distance to nn in training set\")\n",
    "ax[0].set_ylabel(\"Prediction error\")\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[0].set_title(f\"Best model prediction error vs\\ntanimoto dist to training set\")\n",
    "# for models without uncertainty, comment this out\n",
    "sns.scatterplot(x='nnd_train', y=f'{response_col}_std', data=test, ax=ax[1])\n",
    "ax[1].set_xlabel(\"Tanimoto distance to nn in training set\")\n",
    "ax[1].set_ylabel(\"Uncertainty\")\n",
    "ax[1].set_xlim(0, 1)\n",
    "ax[1].set_title(f\"Best model uncertainty vs\\ntanimoto dist to training set\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7pzY9XCCK6N"
   },
   "source": [
    "# Predict on new compounds and explore (regression models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elI4Y_0k7Tbt"
   },
   "source": [
    "#### Generate predictions on a list of compounds from another target (such as provided by your partners)\n",
    "- there will be activity values associated with this target. You can explore overlaps between the two targets\n",
    "- here, my best models are predicting activity of the serotonin receptor, HTR3A\n",
    "- i will compare with data from the serotonin transporter, SLC6A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvOg-pnn3zLN"
   },
   "outputs": [],
   "source": [
    "from atomsci.ddm.utils import curate_data\n",
    "from atomsci.ddm.utils import struct_utils as su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpq6ZY6cyPgT"
   },
   "outputs": [],
   "source": [
    "# new data must have curated smiles strings, with rdkit standardization, featurizations, etc.\n",
    "newcmpds = pd.read_csv(\"/content/drive/MyDrive/Columbia_E4511/SLC6A4_chembl.csv\", sep=\";\")\n",
    "newcmpds = curate_data.average_and_remove_duplicates('pChEMBL Value', 100, False, data=newcmpds, compound_id='Molecule ChEMBL ID', smiles_col='Smiles')\n",
    "newcmpds['base_rdkit_smiles']=su.base_smiles_from_smiles(newcmpds.Smiles.tolist())\n",
    "newcmpds = newcmpds.rename(columns = {'Molecule ChEMBL ID':'compound_id'})\n",
    "newcmpds = cd.aggregate_assay_data(newcmpds, value_col='VALUE_NUM_mean', output_value_col='VALUE_NUM_mean', label_actives=True, active_thresh=7, id_col='compound_id', smiles_col='base_rdkit_smiles', relation_col = 'Standard Relation')\n",
    "newcmpds = newcmpds[~newcmpds.base_rdkit_smiles.isna()]\n",
    "newcmpds = newcmpds[~newcmpds.VALUE_NUM_mean.isna()]\n",
    "newcmpds = newcmpds[newcmpds.VALUE_NUM_mean!='']\n",
    "newcmpds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFuFxQ-zUi-2"
   },
   "outputs": [],
   "source": [
    "ecfp_input_df = newcmpds\n",
    "rms_pred = predict_from_model_file(model_path= rms_model_path, input_df=ecfp_input_df, id_col='compound_id', smiles_col = 'base_rdkit_smiles', \n",
    "                            response_col = 'VALUE_NUM_mean', is_featurized = False, dont_standardize=True)\n",
    "mae_pred = predict_from_model_file(model_path= mae_model_path, input_df=ecfp_input_df, id_col='compound_id', smiles_col = 'base_rdkit_smiles', \n",
    "                            response_col = 'VALUE_NUM_mean', is_featurized = False, dont_standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XteyHtRBUud8"
   },
   "outputs": [],
   "source": [
    "# remember - VALUE_NUM_MEAN_actual here is the IC50 values for target SLC6A4 (that's where the dataset comes from)\n",
    "# SLC6A4 is a serotonin transporter\n",
    "# HTR3A is a serotonin receptor\n",
    "# related targets, but not the same. Will be interesting to see overlaps in activity\n",
    "display(rms_pred.head(), mae_pred.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiCmFkLJ7PQN"
   },
   "source": [
    "#### Visualize predictions that don't have ground truth associated with them\n",
    "- what do the distributions look like? how do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftFbsKJ6VZmF"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, sharex=True, sharey=True, figsize = (10,5))\n",
    "rms_pred.hist('VALUE_NUM_mean_pred', bins=10, ax=ax[0])\n",
    "ax[0].set_title('R2/RMS model')\n",
    "mae_pred.hist('VALUE_NUM_mean_pred', bins=8, ax = ax[1])\n",
    "ax[1].set_title('MAE model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBIsK_xJWgBS"
   },
   "source": [
    "#### Tanimoto distance from train to new compounds\n",
    "- what does a tanimoto distance of zero represent?\n",
    "- what do you think about the distances between your training data and the new data? are the compounds similar or different?\n",
    "- what do you think this means for the uncertainty of new predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9sKejut7-xy"
   },
   "outputs": [],
   "source": [
    "from atomsci.ddm.pipeline import chem_diversity as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3xX4_gNXUQu"
   },
   "outputs": [],
   "source": [
    "htr3a=h1\n",
    "calc_type='nearest'\n",
    "dist_metric='tanimoto'\n",
    "smiles_lst2=newcmpds.base_rdkit_smiles.tolist()\n",
    "htr3a=htr3a.merge(split_df, left_on='compound_id', right_on='cmpd_id')\n",
    "smiles_lst1=htr3a[htr3a.subset=='train'].base_rdkit_smiles.tolist()\n",
    "dists=cd.calc_dist_smiles('ECFP',dist_metric,smiles_lst2,smiles_lst1,calc_type)\n",
    "distsdf=pd.DataFrame([smiles_lst2,list(dists)], columns=range(len(smiles_lst2)), index=['smiles','dists']).T\n",
    "df=newcmpds\n",
    "df=df.merge(distsdf, left_on='base_rdkit_smiles', right_on='smiles')\n",
    "print(len(set(smiles_lst2)-set(smiles_lst1)))\n",
    "print(list(df.loc[df.dists==0, 'compound_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oW9P5wasVxDl"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(10,10))\n",
    "sns.distplot(dists, ax=axes, bins=np.arange(-0.05,1,0.05))\n",
    "axes.set_title(\"Tanimoto distance of compounds to training set of best models\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W9XMW2Y9jn4"
   },
   "source": [
    "#### Uncertainty of new predictions\n",
    "- do you see a correlation between uncertainty and magnitude of prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxanb9SV9i_9"
   },
   "outputs": [],
   "source": [
    "pred_df=mae_pred\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "sns.scatterplot(x=f'{response_col}_pred', y=f'{response_col}_std',  data=pred_df, ax=ax);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovfwBtBzAPjd"
   },
   "source": [
    "#### Uncertainty vs tanimoto distance\n",
    "- do you see correlations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm_CfKZo__I0"
   },
   "outputs": [],
   "source": [
    "pred_df=mae_pred\n",
    "pred_df=pred_df.merge(df)\n",
    "fig, ax = plt.subplots(1,figsize=(10,10))\n",
    "# for models without uncertainty, comment this out\n",
    "sns.scatterplot(x='dists', y=f'{response_col}_std', data=pred_df, ax=ax)\n",
    "ax.set_xlabel(\"Tanimoto distance to nn in training set\")\n",
    "ax.set_ylabel(\"Uncertainty\")\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_title(f\"Best model uncertainty vs\\ntanimoto dist to training set\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v8A6PfRBUEm"
   },
   "source": [
    "#### Compare predictions for your target vs ground truth for another target\n",
    "- do you see any compounds that are selective for your target or the other target? \n",
    "  - you can define selectivity as 1000x more potent for one target vs another, so 3 units of pXC50 values\n",
    "- How similar are the compound activities for the two targets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x53NFOezEEyC"
   },
   "outputs": [],
   "source": [
    "rms_pred['selective'] = abs(rms_pred.VALUE_NUM_mean_actual - rms_pred.VALUE_NUM_mean_pred)>3\n",
    "mae_pred['selective'] = abs(mae_pred.VALUE_NUM_mean_actual - mae_pred.VALUE_NUM_mean_pred)>3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2jSGSJtBhb-"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(18,9))\n",
    "sns.scatterplot(data=rms_pred, x=f'{response_col}_actual', y=f'{response_col}_pred', ax=ax[0], hue='selectivity', legend=False)\n",
    "sns.scatterplot(data=mae_pred, x=f'{response_col}_actual', y=f'{response_col}_pred', ax=ax[1], hue = 'selectivity', legend=False)\n",
    "ax[0].set_xlim([2,12]); ax[0].set_ylim([2,12])\n",
    "ax[1].set_xlim([2,12]); ax[1].set_ylim([2,12])\n",
    "ax[0].set_title('R2/RMS model')\n",
    "ax[1].set_title('MAE model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wA0R-c7-yDil"
   },
   "source": [
    "# Choose best model and examine predictions (classification models)\n",
    "Metrics to assess classification models: (google definitions)\n",
    "- cross_entropy\n",
    "- kappa\n",
    "- matthews_cc\n",
    "- npv\n",
    "- prc_auc_score\n",
    "- precision\n",
    "- recall_score\n",
    "- roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlzn34kmzCH1"
   },
   "source": [
    "#### select best models & visualize metrics with radar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l35TSawFyQwd"
   },
   "outputs": [],
   "source": [
    "# best models per metric\n",
    "top_xnt_model = perf_df[perf_df.valid_cross_entropy==perf_df.valid_cross_entropy.min()] # minimize cross entropy, maximize rest\n",
    "top_kap_model = perf_df[perf_df.valid_kappa==perf_df.valid_kappa.max()]\n",
    "top_mcc_model = perf_df[perf_df.valid_matthews_cc==perf_df.valid_matthews_cc.max()]\n",
    "top_npv_model = perf_df[perf_df.valid_npv==perf_df.valid_npv.max()]\n",
    "top_prc_model = perf_df[perf_df.valid_prc_auc_score==perf_df.valid_prc_auc_score.max()]\n",
    "top_pre_model = perf_df[perf_df.valid_precision==perf_df.valid_precision.max()]\n",
    "top_rec_model = perf_df[perf_df.valid_recall_score==perf_df.valid_recall_score.max()]\n",
    "top_roc_model = perf_df[perf_df.valid_roc_auc_score==perf_df.valid_roc_auc_score.max()] \n",
    "\n",
    "display(top_xnt_model, top_kap_model, top_mcc_model, top_npv_model, top_prc_model, top_pre_model, top_rec_model, top_roc_model)\n",
    "# note: only two different model_uuids here; note featurizer & featurizer types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxDUw6wdFDH6"
   },
   "source": [
    "# Explore the domain of applicability of your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfXL5qPfTGsA"
   },
   "source": [
    "#### Make sure you have featurized data to use for UMAPs\n",
    "graphconv you can't do umaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtbCZY0oSVbo"
   },
   "outputs": [],
   "source": [
    "newcmpds.to_csv(\"/content/drive/MyDrive/Columbia_E4511/SLC6A4_chembl_cur.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_2PC8VRFCiM"
   },
   "outputs": [],
   "source": [
    "# to create umaps on training data, you need features for the model type.\n",
    "# rdkit and mordred should already be featurized if you built models with them\n",
    "# ecfp doesn't have saved features, so extract them now for the training data and new data\n",
    "# just change the train_file to featurize the other dataset\n",
    "from atomsci.ddm.pipeline import featurization as feat\n",
    "\n",
    "train_file = \"/content/drive/MyDrive/Columbia_E4511/SLC6A4_chembl_cur.csv\"\n",
    "response_col = \"VALUE_NUM_mean\"\n",
    "compound_id = \"compound_id\"\n",
    "smiles_col = \"base_rdkit_smiles\"\n",
    "result_dir = \"/content/drive/MyDrive/Columbia_E4511/HTR3A_models\"\n",
    "params = {\n",
    "        \"system\": \"LC\",\n",
    "        \"lc_account\": 'None',\n",
    "        \"datastore\": \"False\",\n",
    "        \"save_results\": \"False\",\n",
    "        \"data_owner\": \"username\",\n",
    "        \"dataset_key\": train_file,\n",
    "        \"id_col\": compound_id,\n",
    "        \"smiles_col\": smiles_col,\n",
    "        \"response_cols\": response_col,\n",
    "        \"previously_split\": \"False\",\n",
    "        \"split_only\": \"True\",\n",
    "        # \"model_type\": \"RF\",\n",
    "        \"verbose\": \"True\",\n",
    "        \"transformers\": \"True\",\n",
    "        'max_epochs': '70',\n",
    "        \"rerun\": \"False\",\n",
    "        \"result_dir\": result_dir,\n",
    "        \"featurizer\":\"ecfp\"\n",
    "    }\n",
    "pparams = parse.wrapper(params)\n",
    "MP = mp.ModelPipeline(pparams)\n",
    "featurization=None\n",
    "# comment out this line after splitting once so you don't re-split\n",
    "MP.run_mode = 'training'\n",
    "MP.params.split_only = True\n",
    "MP.params.previously_split = False\n",
    "if featurization is None:\n",
    "    featurization = feat.create_featurization(MP.params)\n",
    "MP.featurization = featurization\n",
    "MP.load_featurize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtDpWji1Q7_k"
   },
   "outputs": [],
   "source": [
    "ecfp = MP.data.dataset.X\n",
    "y=MP.data.dataset.y\n",
    "ids=MP.data.dataset.ids\n",
    "yids = [ids, y]\n",
    "yids.extend(ecfp.T)\n",
    "ecfpfeats = pd.DataFrame(yids).T\n",
    "ecfp_colnames = ['compound_id', 'mol_wt']\n",
    "col2 = list(range(0,1024))\n",
    "col2 = ['ecfp_'+ str(x) for x in col2]\n",
    "ecfp_colnames.extend(col2)\n",
    "ecfpfeats.columns = ecfp_colnames\n",
    "ecfpfeats.to_csv('/content/drive/MyDrive/Columbia_E4511/scaled_descriptors/SLC6A4_chembl_cur_with_ecfp_descriptors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NU4Q5r5Ca9s-"
   },
   "source": [
    "#### UMAP projection of new compounds onto the training dataset\n",
    "- create umap of training data\n",
    "- use the mapper object to project new compounds onto the training data\n",
    "- visualize prediction uncertainty or ADI as hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilDPPJRPa9Il"
   },
   "outputs": [],
   "source": [
    "display(top_r2_model, top_rms_model, top_mae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7W_UyvbZACR"
   },
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aU11SnzpZJGq"
   },
   "outputs": [],
   "source": [
    "cols_dict={\n",
    "    'ecfp':('ecfp_0','ecfp_1023'),\n",
    "    'mordred_filtered':('ABC','SsBr'),\n",
    "    'rdkit_raw':('MaxEStateIndex','fr_urea'),\n",
    "}\n",
    "# features model was created on, for training data\n",
    "feat_type = 'ecfp'\n",
    "feats = pd.read_csv(f\"/content/drive/MyDrive/Columbia_E4511/scaled_descriptors/HTR3A_curated_with_{feat_type}_descriptors.csv\")\n",
    "valuecol=[f'VALUE_NUM_mean']\n",
    "feats = feats.merge(split_df, left_on='compound_id', right_on='cmpd_id')\n",
    "feats = feats.merge(h1)\n",
    "feats = feats[feats.subset=='train']\n",
    "feats = feats.dropna(subset = valuecol).reset_index(drop=True)\n",
    "# select only the non-na feature columns to run umap on\n",
    "firstcol, lastcol=cols_dict[feat_type]\n",
    "maptrain = feats.loc[:,firstcol:lastcol]\n",
    "maptrain = maptrain.dropna(axis='columns')\n",
    "maptraincols = maptrain.columns\n",
    "# get same feature columns from new compound df\n",
    "featnew=pd.read_csv(f\"/content/drive/MyDrive/Columbia_E4511/scaled_descriptors/SLC6A4_chembl_cur_with_{feat_type}_descriptors.csv\", index_col=False)\n",
    "featnew=featnew.merge(mae_pred)\n",
    "mapnew = featnew.loc[:,firstcol:lastcol]\n",
    "mapnew = mapnew.dropna(axis='columns')\n",
    "mapnewcols = mapnew.columns\n",
    "allcols = list(set(maptraincols).intersection(set(mapnewcols)))\n",
    "maptrain = maptrain[allcols]\n",
    "mapnew= mapnew[allcols]\n",
    "# create umap on training data\n",
    "mapper=umap.UMAP(n_neighbors=15, n_components=2, metric='jaccard', random_state=42).fit(maptrain)\n",
    "maptrain_coords = pd.DataFrame(mapper.embedding_, columns=('UMAP_X', 'UMAP_Y'))\n",
    "feats=pd.concat([feats,maptrain_coords], axis=1)\n",
    "# use mapper to create umap coords for new data\n",
    "mapnew_coords = pd.DataFrame(mapper.transform(mapnew), columns = ('UMAP_X', 'UMAP_Y'))\n",
    "featnew=pd.concat([featnew,mapnew_coords], axis=1)\n",
    "featnew=featnew.merge(newcmpds)\n",
    "featnew=featnew.sort_values('active')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvW-7nAF5L_y"
   },
   "source": [
    "- Do you see any observations about your predictions being more uncertain when they are more isolated or further away from other things in the UMAP projection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLRArnKZeLKk"
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(30,15), gridspec_kw={'width_ratios': [1, 1.2]})\n",
    "# plot with active / inactive labels\n",
    "sns.scatterplot(x=feats['UMAP_X'], y=feats[\"UMAP_Y\"], s=50, hue=feats['active'].map({0:False, 1:True}), palette=['#e0e0e0','#b3b3b3'], ax=ax[0])\n",
    "sns.scatterplot(x=featnew['UMAP_X'], y=featnew[\"UMAP_Y\"], hue=featnew[f'VALUE_NUM_mean_pred']>7, palette='Set2', marker = '^', legend='full', ax=ax[0])\n",
    "handles, _ = ax[0].get_legend_handles_labels()\n",
    "ax[0].legend([handles[1],handles[-1]], [f'Training Hits', f'Pred Hits'], fontsize=12)\n",
    "ax[0].set_title(f'Hits on {feat_type} training data UMAP (n={len(feats)})')\n",
    "# plot with continuous labels\n",
    "valcol=f'VALUE_NUM_mean_std'\n",
    "# reduce number of points to plot\n",
    "plotnew = featnew[featnew[valcol]>1.8]\n",
    "norm = plt.Normalize(plotnew[valcol].min(), plotnew[valcol].max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "sm.set_array([])\n",
    "sns.scatterplot(x=feats['UMAP_X'], y=feats[\"UMAP_Y\"], s=50, hue=feats['active'], palette=['#e0e0e0','#b3b3b3'], ax=ax[1])\n",
    "sns.scatterplot(x=plotnew['UMAP_X'], y=plotnew[\"UMAP_Y\"], hue=plotnew[valcol], palette='viridis', marker = '^', ax=ax[1]);\n",
    "# Remove the legend and add a colorbar\n",
    "ax[1].get_legend().remove()\n",
    "ax[1].figure.colorbar(sm)\n",
    "ax[1].set_title(f'Compound unc. on {feat_type} training data UMAP (n={len(feats)})');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skmbXOruqeLF"
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "08_AMPL_EDA_Part2.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
