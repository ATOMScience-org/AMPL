{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f70f3f5",
   "metadata": {},
   "source": [
    "# Train a Simple Regression Model\n",
    "\n",
    "The process of training an ML model involves providing an ML algorithm (that is, the learning algorithm) with training data to learn from. The term ML model refers to the model artifact that is created by the training process. The goal of training a Regression Model is to find those values of weights against which loss function can be minimized i. e difference between the predicted values and the true labels is minimized as much as possible.\n",
    "\n",
    "This tutorial will detial how we can use AMPL tools to train a regression model to predict the pIC50 values of the kcna5 target assay. We will train a Random Forest model using rdkit features of the curated kcna5 data; split the dataset (or use already generated split file); explain the use of descriptors; evaluate the performance of the model; save the model as a .targz file in a preffered location for easy retrieval.\n",
    "\n",
    "Please note that training a Random Forest model and splitting the dataset are inherently non-deterministic. You may obtain a different Random Forest model by running this tutorial each time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddf45a6",
   "metadata": {},
   "source": [
    "# Model Training (using already split data)\n",
    "\n",
    "We will use the curated dataset that we created in tutorial 2 and the split file we created in tutorial 3 and build a json file for training. We set \"previously_split\": \"True and add the split_uuid. Here, we will use \"split_uuid\" : \"bcd96299-6d61-4467-9e6b-814dcf8cde16\"; the uuid for the scaffold split created in tutorial 3.\n",
    "\n",
    "AMPL provides an extensible featurization module that can generate a variety of molecular feature types, given SMILES strings as input. For demonstration purposes, we choose to use rdkit features in this tutorial.\n",
    "\n",
    "When the featurized dataset is not previously saved for curated_kcna5_ic50, AMPL will create a featurized dataset and save it in a folder called scaled_descriptors as a csv file : dataset/scaled_descriptors/curated_kcna5_ic50_with_rdkit_raw_descriptors.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd12dbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gsfs12/users/lup2/AMPL/ampl_tutorials/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/gpfs/gsfs12/users/lup2/AMPL/ampl_tutorials/lib/python3.8/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions.\n",
      "DEBUG:ATOM:Model tracker client not supported in your environment; will save models in filesystem only.\n",
      "INFO:ATOM:Created a dataset hash 'd73e30e5b0ddf05e34665d76e5c62d27' from dataset_key '/gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutorials/atomsci/ddm/examples/tutorials2023/dataset/curated_kcna5_ic50.csv'\n",
      "INFO:ATOM:Reading descriptor spec table from /gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutorials/atomsci/ddm/data/descriptor_sets_sources_by_descr_type.csv\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to dataset/curated_kcna5_ic50/RF_computed_descriptors_scaffold_regression/ebc39cab-fc9f-4238-827e-241850cee82b/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutorials/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.942, validation r2_score = 0.370, test r2_score = 0.205\n",
      "INFO:ATOM:Wrote model tarball to dataset/curated_kcna5_ic50_model_ebc39cab-fc9f-4238-827e-241850cee82b.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# importing relevant libraries\n",
    "import pandas as pd\n",
    "from atomsci.ddm.pipeline import model_pipeline as mp\n",
    "from atomsci.ddm.pipeline import parameter_parser as parse\n",
    "\n",
    "# Set up\n",
    "dataset_file = 'dataset/curated_kcna5_ic50.csv'\n",
    "odir='dataset'\n",
    "\n",
    "response_col = \"avg_pIC50\"\n",
    "compound_id = \"compound_id\"\n",
    "smiles_col = \"base_rdkit_smiles\"\n",
    "\n",
    "params = {\n",
    "        \"verbose\": \"True\",\n",
    "        \"system\": \"LC\",\n",
    "        \"datastore\": \"False\",\n",
    "        \"save_results\": \"False\",\n",
    "        \"prediction_type\": \"regression\",\n",
    "        \"dataset_key\": dataset_file,\n",
    "        \"id_col\": compound_id,\n",
    "        \"smiles_col\": smiles_col,\n",
    "        \"response_cols\": response_col,\n",
    "        \"previously_split\": \"True\",\n",
    "        \"split_uuid\" : \"bcd96299-6d61-4467-9e6b-814dcf8cde16\",\n",
    "        \"split_only\": \"False\",\n",
    "        \"featurizer\": \"computed_descriptors\",\n",
    "        \"descriptor_type\" : \"rdkit_raw\",\n",
    "        \"model_type\": \"RF\",\n",
    "        \"verbose\": \"True\",\n",
    "        \"transformers\": \"True\",\n",
    "        'max_epochs': '70',\n",
    "        \"rerun\": \"False\",\n",
    "        \"result_dir\": odir\n",
    "    }\n",
    "\n",
    "ampl_param = parse.wrapper(params)\n",
    "pl = mp.ModelPipeline(ampl_param)\n",
    "pl.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409083fb",
   "metadata": {},
   "source": [
    "# Model Training (Split data and train)\n",
    "\n",
    "Let us look at how we split the dataset and then train. Here, we set \"previously_split\": \"False\" and not have a split_uuid parameter. AMPL splits the data by the type of split specified in the splitter parameter (here,scaffold) and writes the split file in dataset/curated_kcna5_ic50_train_valid_test_scaffold_{split_uuid}.csv. After training, AMPL saves the model and all of its parameters as a tarball in the result_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5bbc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ATOM:Created a dataset hash 'd73e30e5b0ddf05e34665d76e5c62d27' from dataset_key '/gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutorials/atomsci/ddm/examples/tutorials2023/dataset/curated_kcna5_ic50.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Splitting data by scaffold\n",
      "WARNING:ATOM:Dataset split table saved to /gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutorials/atomsci/ddm/examples/tutorials2023/dataset/curated_kcna5_ic50_train_valid_test_scaffold_a5dac780-f252-4579-97b8-0403a9ef0da4.csv\n",
      "INFO:ATOM:Wrote transformers to dataset/curated_kcna5_ic50/RF_computed_descriptors_scaffold_regression/2d42a29e-4d10-4c88-abfa-3c811eae05ef/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutorials/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.941, validation r2_score = 0.195, test r2_score = 0.396\n",
      "INFO:ATOM:Wrote model tarball to dataset/curated_kcna5_ic50_model_2d42a29e-4d10-4c88-abfa-3c811eae05ef.tar.gz\n"
     ]
    }
   ],
   "source": [
    "response_col = \"avg_pIC50\"\n",
    "compound_id = \"compound_id\"\n",
    "smiles_col = \"base_rdkit_smiles\"\n",
    "\n",
    "params = {\n",
    "        \"verbose\": \"True\",\n",
    "        \"system\": \"LC\",\n",
    "        \"datastore\": \"False\",\n",
    "        \"save_results\": \"False\",\n",
    "        \"prediction_type\": \"regression\",\n",
    "        \"dataset_key\": dataset_file,\n",
    "        \"id_col\": compound_id,\n",
    "        \"smiles_col\": smiles_col,\n",
    "        \"response_cols\": response_col,\n",
    "        \"previously_split\": \"False\",\n",
    "        \"split_only\": \"False\",\n",
    "        \"splitter\": \"scaffold\",\n",
    "        \"split_valid_frac\": \"0.15\",\n",
    "        \"split_test_frac\": \"0.15\",\n",
    "        \"featurizer\": \"computed_descriptors\",\n",
    "        \"descriptor_type\" : \"rdkit_raw\",\n",
    "        \"model_type\": \"RF\",\n",
    "        \"verbose\": \"True\",\n",
    "        \"transformers\": \"True\",\n",
    "        'max_epochs': '70',\n",
    "        \"rerun\": \"False\",\n",
    "        \"result_dir\": odir\n",
    "    }\n",
    "\n",
    "ampl_param = parse.wrapper(params)\n",
    "pl = mp.ModelPipeline(ampl_param)\n",
    "pl.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d4387",
   "metadata": {},
   "source": [
    "# Performance of the model\n",
    "Model performance in machine learning is a measurement of how accurate predictions a model makes on new, unseen data are. We typically measure model performance using a test set, where you compare the predictions on the test set to the actual outcomes.\n",
    "Performance metrics are a part of every machine learning pipeline. They tell you if you’re making progress, and put a number on it.\n",
    "Regression models have continuous output. So, we need a metric based on calculating some sort of distance between predictions and ground truth.\n",
    "\n",
    "Popular metrics to evaluate Regression models are Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE) and R² (R-Squared). We will compare the R2 scores of our models; our top model is one which has the maximum R2 score on the validation set.\n",
    "\n",
    "Please note that the model tracker client will not be supported in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d34b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Model tracker client not supported in your environment; can look at models in filesystem only.\n",
      "WARNING:ATOM:Warning: column names have been changed to align with get_multitask_perf_from_tracker(): featurizer is now features and <subset>_<metric> has been changed to best_<subset>_<metric>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data for 2 models under dataset\n"
     ]
    }
   ],
   "source": [
    "# Model Performance\n",
    "from atomsci.ddm.pipeline import compare_models as cm\n",
    "pred_df = cm.get_filesystem_perf_results(odir, pred_type='regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf89a52",
   "metadata": {},
   "source": [
    "The pred_df dataframe has details about the model_uuid, model_path, ampl_version, model_type, features, splitter and the results for popular metrics that help evaluate the performance. Let us view the contents of the pred_df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605a4f10-17d5-4af1-b2e0-3d040b4fe1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv('./dataset/pred_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7fe7829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_uuid</th>\n",
       "      <th>model_path</th>\n",
       "      <th>ampl_version</th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset_key</th>\n",
       "      <th>features</th>\n",
       "      <th>splitter</th>\n",
       "      <th>model_score_type</th>\n",
       "      <th>feature_transform_type</th>\n",
       "      <th>model_choice_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rf_max_depth</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>layer_sizes</th>\n",
       "      <th>dropouts</th>\n",
       "      <th>xgb_gamma</th>\n",
       "      <th>xgb_learning_rate</th>\n",
       "      <th>model_parameters_dict</th>\n",
       "      <th>feat_parameters_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebc39cab-fc9f-4238-827e-241850cee82b</td>\n",
       "      <td>dataset/curated_kcna5_ic50_model_ebc39cab-fc9f...</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>RF</td>\n",
       "      <td>/gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutori...</td>\n",
       "      <td>rdkit_raw</td>\n",
       "      <td>scaffold</td>\n",
       "      <td>r2</td>\n",
       "      <td>normalization</td>\n",
       "      <td>0.369536</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"rf_estimators\": 500, \"rf_max_depth\": null, \"...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d42a29e-4d10-4c88-abfa-3c811eae05ef</td>\n",
       "      <td>dataset/curated_kcna5_ic50_model_2d42a29e-4d10...</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>RF</td>\n",
       "      <td>/gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutori...</td>\n",
       "      <td>rdkit_raw</td>\n",
       "      <td>scaffold</td>\n",
       "      <td>r2</td>\n",
       "      <td>normalization</td>\n",
       "      <td>0.194591</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"rf_estimators\": 500, \"rf_max_depth\": null, \"...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model_uuid  \\\n",
       "0  ebc39cab-fc9f-4238-827e-241850cee82b   \n",
       "1  2d42a29e-4d10-4c88-abfa-3c811eae05ef   \n",
       "\n",
       "                                          model_path ampl_version model_type  \\\n",
       "0  dataset/curated_kcna5_ic50_model_ebc39cab-fc9f...        1.6.0         RF   \n",
       "1  dataset/curated_kcna5_ic50_model_2d42a29e-4d10...        1.6.0         RF   \n",
       "\n",
       "                                         dataset_key   features  splitter  \\\n",
       "0  /gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutori...  rdkit_raw  scaffold   \n",
       "1  /gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutori...  rdkit_raw  scaffold   \n",
       "\n",
       "  model_score_type feature_transform_type  model_choice_score  ...  \\\n",
       "0               r2          normalization            0.369536  ...   \n",
       "1               r2          normalization            0.194591  ...   \n",
       "\n",
       "   rf_max_depth  max_epochs  best_epoch  learning_rate  layer_sizes  dropouts  \\\n",
       "0          None         NaN         NaN            NaN          NaN       NaN   \n",
       "1          None         NaN         NaN            NaN          NaN       NaN   \n",
       "\n",
       "   xgb_gamma  xgb_learning_rate  \\\n",
       "0        NaN                NaN   \n",
       "1        NaN                NaN   \n",
       "\n",
       "                               model_parameters_dict  feat_parameters_dict  \n",
       "0  {\"rf_estimators\": 500, \"rf_max_depth\": null, \"...                    {}  \n",
       "1  {\"rf_estimators\": 500, \"rf_max_depth\": null, \"...                    {}  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the pred_df dataframe\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6629959c",
   "metadata": {},
   "source": [
    "# Top Performing Model\n",
    "To pick the top performing model, we sort the R2 scores on the validation set in descending order and pick the one that is maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87973dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_uuid                               ebc39cab-fc9f-4238-827e-241850cee82b\n",
       "model_path                  dataset/curated_kcna5_ic50_model_ebc39cab-fc9f...\n",
       "ampl_version                                                            1.6.0\n",
       "model_type                                                                 RF\n",
       "dataset_key                 /gpfs/gsfs12/users/lup2/AMPL/AMPL_setup_tutori...\n",
       "features                                                            rdkit_raw\n",
       "splitter                                                             scaffold\n",
       "model_score_type                                                           r2\n",
       "feature_transform_type                                          normalization\n",
       "model_choice_score                                                   0.369536\n",
       "best_train_r2_score                                                  0.941555\n",
       "best_train_rms_score                                                 0.197274\n",
       "best_train_mae_score                                                 0.147301\n",
       "best_train_num_compounds                                                  561\n",
       "best_valid_r2_score                                                  0.369536\n",
       "best_valid_rms_score                                                 0.711954\n",
       "best_valid_mae_score                                                 0.542613\n",
       "best_valid_num_compounds                                                  120\n",
       "best_test_r2_score                                                   0.205017\n",
       "best_test_rms_score                                                  0.695672\n",
       "best_test_mae_score                                                  0.508501\n",
       "best_test_num_compounds                                                   121\n",
       "rf_estimators                                                             500\n",
       "rf_max_features                                                            32\n",
       "rf_max_depth                                                             None\n",
       "max_epochs                                                                NaN\n",
       "best_epoch                                                                NaN\n",
       "learning_rate                                                             NaN\n",
       "layer_sizes                                                               NaN\n",
       "dropouts                                                                  NaN\n",
       "xgb_gamma                                                                 NaN\n",
       "xgb_learning_rate                                                         NaN\n",
       "model_parameters_dict       {\"rf_estimators\": 500, \"rf_max_depth\": null, \"...\n",
       "feat_parameters_dict                                                       {}\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top performing model\n",
    "top_model=pred_df.sort_values(by=\"best_valid_r2_score\", ascending=False).iloc[0,:]\n",
    "top_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7761e8",
   "metadata": {},
   "source": [
    "# Model tarball \n",
    "The model_path or the location of the tarball where the top performing model is saved is in top_model.model_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5022c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/curated_kcna5_ic50_model_ebc39cab-fc9f-4238-827e-241850cee82b.tar.gz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top performing model path\n",
    "top_model.model_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ampl_tutorials",
   "language": "python",
   "name": "ampl_tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
